{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, LearningCurveDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar los Mejores Hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir los datos en las variables de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y']\n",
    "X = df.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty' : ['none', 'l1', 'l2', 'elasticinet'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'max_iter' : [100, 1000, 2500, 5000]\n",
    "}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(logReg, param_grid = param_grid, cv = 3, verbose = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'La mejor exactitud: {best_clf.score(X, y):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de Aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(C = 0.0001, penalty = 'l1', solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningCurveDisplay.from_estimator(logReg, X, y, cv = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestra curva de aprendizaje, podemos notar que nuestro modelo a medida que aumenta el tamaño de los datos de entrenamiento este poco a poco esta generalizando mas los datos, es decir, la distancia entre las curvas de aprendizaje y validación es cada vez menor, sin embargo, a su vez vemos que la curva de validacion se quedo estancada en un valor, y esta no se mueve (o al menos no se puede apreciar el movimiento de esta).\n",
    "<br>\n",
    "Una de las primeras conclusiones que podemos sacar es que nuestro modelo no sufre de overfitting o underfitting, esto debido a que nuestras curvas de aprendizaje convergen a un valor y al final no se puede apreciar una diferencia entre estas.\n",
    "<br>\n",
    "El hecho de que la curva de validacion no se mueva puede deverse a cosas como que el modelo es muy simple y no es capaz de aprender mas sobre los datos, o que los datos que tenemos no son suficientes para poder predecir nuestras variables adecuadamente.\n",
    "<br>\n",
    "<br>\n",
    "Recomendaciones:\n",
    "* Recolectar una mayor cantidad de datos, los cuales no dependan de contacto previo con los clientes, como puede ser, cantidad de productos financieros que ha tenido en su vida, estados financieros de personas allegadas a este, etc; esto debido a que debido a lo simple y generales que son nuestros datos finales que escogimos, estos no puedan estar dando un patron (o tal vez puede ser el siguiente punto) muy claro, o no estan dando informacion suficiente para poder realizar una prediccion mas acertada.\n",
    "* Probar con otros modelos de clasificacion mas complejos, puede ser que nuestro modelo de regresion logistica sea demasiado simple para poder capturar los patrones que tienen nuestros datos, si esto fuera cierto, haria que no importa cuanta mayor cantidad de datos le metamos, el porcentaje de aciertos (de los datos de validacion) no aumentaria.\n",
    "\n",
    "En resumen de las recomendaciones para este modelo, serian hacer una mayor recoleccion de caracteristicas de los clientes e intentar usar otros modelos mas complejos.\n",
    "\n",
    "`Nota: cabe recalcar que cuando digo recolectar mas caracteristicas, me refiero a mas columnas, no necesariamente aumentar la cantidad de filas, aunque por obvias razones, mientras mas filas mejor.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
