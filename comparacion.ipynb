{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, LearningCurveDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv')\n",
    "y = df['y']\n",
    "X = df.drop('y', axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 234, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los modelos con los parametros previamente encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(C = 0.0001, penalty = 'l1', solver = 'liblinear')\n",
    "ranForest = RandomForestClassifier(max_depth = 2, n_estimators = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg.fit(X_train, y_train)\n",
    "ranForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compararacion de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de hacer estas comparacion, cabe recalcar que por el objetivo y el contexto de los datos, el lo que debemos de hacer es minimizar los Falsos Negativos, esto debido a que sera para un banco peor el perder posibles ganancias por no haber llamado a una persona, que tener un costo marginal mas bajo de contactar a una persona que el modelo incorrectamente predijo que si iba a contratar (esto porque existe la posibilidad, por mas remota de que sea, que efectivamente lo haga), es decir, es mejor pecar por intentar contactar de mas, que perder por no contactar.\n",
    "\n",
    "Es decir, para nosotros la metrica mas importante es el `recall`.\n",
    "\n",
    "Ademas, no vamos a usar la curva ROC devido a que como se vio en nuestra exploracion de datos, el dataset no esta balanceado, esto debido a que a duras penas hay personas que abrieron un CDT en comparacion con las que no lo hicieron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, roc_curve, auc, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predLogReg = logReg.predict(X_test)\n",
    "predLogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predRanForest = ranForest.predict(X_test)\n",
    "predRanForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kohen-Cappa Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este test va a servir para determinar que tan cercanas son o que tanto difieren las predicciones de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(predLogReg, predRanForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto que se esta viendo con el Kohen-Cappa test es un gran problema, esto esta dando indicaciones de que los modelos solo estan prediciendo `no` a todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporte de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predLogReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predRanForest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos reportes de clasificacion estan demostrando lo que se temia, los modelos no estan prediciendo como deberian, solamente estan diciendo que `no`.\n",
    "\n",
    "Esto se puede deber a que como previamente fue mencionado en los diagnosticos de los modelos anteriores, la calidad de los datos no es suficiente.\n",
    "\n",
    "Se va a mostrar de igual manera las matrices de confucion, pero ya se puede concluir que los modelos no son usables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices de confucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predLogReg)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "font={'size':'15'}\n",
    "plt.rc('font',**font)\n",
    "plt.rcParams['figure.figsize']=[6,6]\n",
    "disp.plot(cmap='Blues',values_format='0.2f')\n",
    "plt.gca().axes.get_xaxis().set_ticks([])\n",
    "plt.gca().axes.get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predRanForest)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "font={'size':'15'}\n",
    "plt.rc('font',**font)\n",
    "plt.rcParams['figure.figsize']=[6,6]\n",
    "disp.plot(cmap='Blues',values_format='0.2f')\n",
    "plt.gca().axes.get_xaxis().set_ticks([])\n",
    "plt.gca().axes.get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente ninguno de los dos modelos estan funcionando bien. Solo estan diciendo que `no` a todo, lo cual no solo es erroneo, si no que hace que el nivel de Falsos Negativos sea muy alto.\n",
    "\n",
    "Lo que se deberia de hacer es mejorar la calidad de los datos, por medio de recoger datos los cuales sean mas especificos, y si que en verdad puedan representar a diferentes poblaciones con diferentes caracteristicas, y de esa manera ahi si se podria hacer un modelo realmente util.\n",
    "\n",
    "Pero tal como estan nuestros datos, no se puede realizar un modelo de prediccion con el cual el banco, sin ningun contacto previo con el posible cliente, pueda predecir de manera acertada (o al menos aceptable) si dicho posible cliente va a abrir un CDT o no"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
